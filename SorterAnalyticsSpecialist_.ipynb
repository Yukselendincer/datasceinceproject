{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMryu53c6np8D1Jcbk9tWD0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yukselendincer/datasceinceproject/blob/main/SorterAnalyticsSpecialist_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Dosya yolunu belirtiyoruz\n",
        "file_path = \"DataCoSupplyChainDataset.csv\"\n",
        "\n",
        "# Veriyi yÃ¼kle (encoding='latin-1' ekleyerek hata giderildi)\n",
        "df = kagglehub.dataset_load(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"shashwatwork/dataco-smart-supply-chain-for-big-data-analysis\",\n",
        "  file_path,\n",
        "  pandas_kwargs={\"encoding\": \"latin-1\"}\n",
        ")\n",
        "\n",
        "# Ä°lk 5 kaydÄ± kontrol et\n",
        "print(\"Veri baÅŸarÄ±yla yÃ¼klendi!\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "yApl5cBraqE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Veriyi yÃ¼kle (Daha Ã¶nce konuÅŸtuÄŸumuz encoding ayarÄ± ile)\n",
        "file_path = \"DataCoSupplyChainDataset.csv\"\n",
        "df = kagglehub.dataset_load(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"shashwatwork/dataco-smart-supply-chain-for-big-data-analysis\",\n",
        "    file_path,\n",
        "    pandas_kwargs={\"encoding\": \"latin-1\"}\n",
        ")\n",
        "\n",
        "# 2. Tarih kolonlarÄ±nÄ± datetime formatÄ±na Ã§evir\n",
        "df['order_date'] = pd.to_datetime(df['order date (DateOrders)'])\n",
        "df['shipping_date'] = pd.to_datetime(df['shipping date (DateOrders)'])\n",
        "\n",
        "# 3. Ä°ÅŸlem SÃ¼resi (Processing Time) Hesaplama\n",
        "# SipariÅŸin verilmesi ile kargoya verilmesi arasÄ±nda geÃ§en gerÃ§ek gÃ¼n sayÄ±sÄ±\n",
        "df['actual_processing_days'] = (df['shipping_date'] - df['order_date']).dt.days\n",
        "\n",
        "# 4. Gecikme Analizi (Scheduled vs Real)\n",
        "# Planlanan sÃ¼reden daha uzun sÃ¼ren iÅŸlemleri iÅŸaretle\n",
        "df['delay_amount'] = df['Days for shipping (real)'] - df['Days for shipment (scheduled)']\n",
        "df['is_late'] = df['delay_amount'] > 0\n",
        "\n",
        "# 5. Sorter VerimliliÄŸi Ä°Ã§in DarboÄŸaz Analizi\n",
        "# Hangi kategorilerde veya hangi gÃ¼nlerde yÄ±ÄŸÄ±lma var?\n",
        "bottleneck_analysis = df.groupby('Category Name').agg({\n",
        "    'actual_processing_days': 'mean',\n",
        "    'is_late': 'sum',\n",
        "    'Order Id': 'count'\n",
        "}).rename(columns={'Order Id': 'Total_Orders'}).sort_values(by='actual_processing_days', ascending=False)\n",
        "\n",
        "print(\"--- Ä°lk 5 SatÄ±r ---\")\n",
        "print(df[['order_date', 'shipping_date', 'actual_processing_days', 'Days for shipment (scheduled)', 'is_late']].head())\n",
        "\n",
        "print(\"\\n--- Kategori BazlÄ± DarboÄŸaz Analizi ---\")\n",
        "print(bottleneck_analysis.head(10))\n",
        "\n",
        "# 6. Basit Hacim SimÃ¼lasyonu (Ã–rnek)\n",
        "# GÃ¼nlÃ¼k sipariÅŸ hacmini hesaplayalÄ±m\n",
        "daily_orders = df.groupby(df['order_date'].dt.date).size()\n",
        "current_max_capacity = daily_orders.mean() * 1.2  # Mevcut ortalamanÄ±n %20 fazlasÄ±nÄ± kapasite sayalÄ±m\n",
        "\n",
        "print(f\"\\nGÃ¼nlÃ¼k Ortalama SipariÅŸ: {daily_orders.mean():.2f}\")\n",
        "print(f\"VarsayÄ±lan Sorter Kapasitesi: {current_max_capacity:.2f}\")"
      ],
      "metadata": {
        "id": "n1OhFPtIengj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. GÃ¼nlÃ¼k SipariÅŸ Hacmini Hesapla\n",
        "daily_demand = df.groupby(df['order_date'].dt.date).size().reset_index()\n",
        "daily_demand.columns = ['date', 'order_count']\n",
        "\n",
        "# 2. Sorter SimÃ¼lasyon Fonksiyonu\n",
        "def run_sorter_simulation(demand_data, capacity_increase_factor=1.0, demand_spike_factor=1.2):\n",
        "    \"\"\"\n",
        "    capacity_increase_factor: Mevcut kapasiteyi ne kadar artÄ±rdÄ±ÄŸÄ±mÄ±z (1.0 = deÄŸiÅŸim yok)\n",
        "    demand_spike_factor: SipariÅŸ hacmindeki artÄ±ÅŸ (%20 artÄ±ÅŸ iÃ§in 1.2)\n",
        "    \"\"\"\n",
        "    # Mevcut ortalama kapasiteyi baz alalÄ±m (GÃ¼nlÃ¼k ortalama sipariÅŸin %110'u kapasitemiz olsun)\n",
        "    base_capacity = demand_data['order_count'].mean() * 1.1 * capacity_increase_factor\n",
        "\n",
        "    backlog = 0  # Biriken/YetiÅŸmeyen sipariÅŸ\n",
        "    results = []\n",
        "\n",
        "    for orders in demand_data['order_count']:\n",
        "        current_demand = orders * demand_spike_factor + backlog\n",
        "\n",
        "        if current_demand > base_capacity:\n",
        "            shipped = base_capacity\n",
        "            backlog = current_demand - base_capacity\n",
        "        else:\n",
        "            shipped = current_demand\n",
        "            backlog = 0\n",
        "\n",
        "        results.append({\n",
        "            'Demand': current_demand,\n",
        "            'Shipped': shipped,\n",
        "            'Backlog': backlog\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results), base_capacity\n",
        "\n",
        "# 3. SimÃ¼lasyonu Ã‡alÄ±ÅŸtÄ±r (%20 Talep ArtÄ±ÅŸÄ± Senaryosu)\n",
        "sim_df, daily_cap = run_sorter_simulation(daily_demand, demand_spike_factor=1.2)\n",
        "\n",
        "# 4. SonuÃ§larÄ± GÃ¶rselleÅŸtir\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(sim_df['Backlog'], color='red', label='Biriken SipariÅŸ (Backlog)')\n",
        "plt.axhline(y=daily_cap, color='green', linestyle='--', label='GÃ¼nlÃ¼k Sorter Kapasitesi')\n",
        "plt.title('SipariÅŸ Hacmi %20 Artarsa Depo Backlog Durumu')\n",
        "plt.xlabel('GÃ¼nler')\n",
        "plt.ylabel('SipariÅŸ SayÄ±sÄ±')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 5. Raporlama\n",
        "print(f\"GÃ¼nlÃ¼k Sorter Kapasitesi: {daily_cap:.0f} birim\")\n",
        "print(f\"SimÃ¼lasyon Sonu Toplam Biriken (YetiÅŸmeyen) SipariÅŸ: {sim_df['Backlog'].sum():.0f}\")\n",
        "print(f\"Ortalama GÃ¼nlÃ¼k Gecikme: {sim_df['Backlog'].mean():.2f} sipariÅŸ\")"
      ],
      "metadata": {
        "id": "XrUQ6OnjgxQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Dashboard iÃ§in ana metrikleri iÃ§eren tabloyu oluÅŸturalÄ±m\n",
        "dashboard_data = df.groupby(['Category Name', 'Order Region', 'is_late']).agg({\n",
        "    'Order Id': 'count',\n",
        "    'Sales': 'sum',\n",
        "    'actual_processing_days': 'mean',\n",
        "    'Benefit per order': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# SÃ¼tun isimlerini dashboard dostu yapalÄ±m\n",
        "dashboard_data.columns = ['Kategori', 'Bolge', 'Gecikme_Durumu', 'Siparis_Sayisi', 'Toplam_Satis', 'Ort_Islem_Suresi', 'Toplam_Kar']\n",
        "\n",
        "# DosyayÄ± Excel veya CSV olarak kaydet (Power BI/Tableau'ya yÃ¼klemek iÃ§in)\n",
        "dashboard_data.to_csv(\"dashboard_hazir_veri.csv\", index=False)\n",
        "print(\"Dashboard verisi 'dashboard_hazir_veri.csv' olarak kaydedildi!\")"
      ],
      "metadata": {
        "id": "yEtnzm0GigR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# 1. Gecikme OranlarÄ± (Kategorik)\n",
        "fig1 = px.bar(dashboard_data, x='Kategori', y='Siparis_Sayisi', color='Gecikme_Durumu',\n",
        "             title=\"Kategori BazlÄ± Gecikme DaÄŸÄ±lÄ±mÄ±\", barmode='group')\n",
        "fig1.show()\n",
        "\n",
        "# 2. BÃ¶lgesel SatÄ±ÅŸ ve Lojistik Performans\n",
        "fig2 = px.scatter(dashboard_data, x='Ort_Islem_Suresi', y='Toplam_Satis',\n",
        "                 size='Siparis_Sayisi', color='Bolge', hover_name='Kategori',\n",
        "                 title=\"Ä°ÅŸlem SÃ¼resi vs SatÄ±ÅŸ Hacmi (BÃ¶lgesel)\")\n",
        "fig2.show()"
      ],
      "metadata": {
        "id": "MgLa0NCD9lJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1. Ã–zellik SeÃ§imi (Features) ve Hedef DeÄŸiÅŸken (Target)\n",
        "# Tahmin yaparken 'sipariÅŸ verildikten sonra oluÅŸan' verileri (gerÃ§ek teslimat gÃ¼nÃ¼ gibi) kullanmamalÄ±yÄ±z.\n",
        "features = [\n",
        "    'Type', 'Days for shipment (scheduled)', 'Sales per customer',\n",
        "    'Category Name', 'Order City', 'Order Region', 'Shipping Mode'\n",
        "]\n",
        "X = df[features].copy()\n",
        "y = df['Late_delivery_risk'] # 1: Gecikme riski var, 0: Yok\n",
        "\n",
        "# 2. Kategorik Verileri SayÄ±sallaÅŸtÄ±rma (Encoding)\n",
        "le = LabelEncoder()\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    X[col] = le.fit_transform(X[col])\n",
        "\n",
        "# 3. EÄŸitim ve Test Setine AyÄ±rma\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Model Kurulumu (Random Forest)\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Tahmin ve DeÄŸerlendirme\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"--- Model PerformansÄ± ---\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# 6. Ã–nemli Ã–zellikler (Hangi faktÃ¶r gecikmeyi en Ã§ok etkiliyor?)\n",
        "feature_importance = pd.DataFrame({'Feature': features, 'Importance': model.feature_importances_})\n",
        "print(\"\\n--- Gecikmeyi Etkileyen En Ã–nemli FaktÃ¶rler ---\")\n",
        "print(feature_importance.sort_values(by='Importance', ascending=False))"
      ],
      "metadata": {
        "id": "g5lmmK3v-BHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# XGBoost Modelini TanÄ±mla\n",
        "xgb_model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=7, random_state=42)\n",
        "\n",
        "# Modeli EÄŸit\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Tahmin Yap\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "print(f\"XGBoost Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
        "print(\"\\n--- Yeni Model PerformansÄ± ---\")\n",
        "print(classification_report(y_test, y_pred_xgb))"
      ],
      "metadata": {
        "id": "CCcz0r-c-a5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_xgb)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('XGBoost Hata Matrisi (Confusion Matrix)')\n",
        "plt.ylabel('GerÃ§ek Durum')\n",
        "plt.xlabel('Modelin Tahmini')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2tDVmOOF_D68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "readme_content = \"\"\"# # ğŸšš Veriye DayalÄ± Tedarik Zinciri ve Lojistik Optimizasyonu\n",
        "\n",
        "Bu proje, **DataCo Global** ÅŸirketinin tedarik zinciri verilerini kullanarak; depo operasyonel verimliliÄŸini artÄ±rmak, teslimat gecikmelerini Ã¶nceden tahmin etmek ve sorter (ayrÄ±ÅŸtÄ±rÄ±cÄ±) sistemlerindeki darboÄŸazlarÄ± simÃ¼le etmek amacÄ±yla geliÅŸtirilmiÅŸtir.\n",
        "\n",
        "## ğŸ“Œ Proje Ã–zeti\n",
        "YÃ¼ksek hacimli lojistik verileri analiz edilerek, teslimat sÃ¼reÃ§lerindeki aksaklÄ±klarÄ±n kÃ¶k nedenleri saptanmÄ±ÅŸ ve **Makine Ã–ÄŸrenmesi (XGBoost)** ile gecikme riski taÅŸÄ±yan sipariÅŸler iÃ§in bir erken uyarÄ± sistemi modellenmiÅŸtir.\n",
        "\n",
        "## ğŸ› ï¸ KullanÄ±lan Teknolojiler\n",
        "* **Veri Analizi:** Python, Pandas, Numpy\n",
        "* **Makine Ã–ÄŸrenmesi:** XGBoost, Random Forest, Scikit-learn\n",
        "* **GÃ¶rselleÅŸtirme:** Matplotlib, Seaborn, Plotly (Dashboard hazÄ±rlÄ±ÄŸÄ±)\n",
        "* **SimÃ¼lasyon:** Python tabanlÄ± kapasite ve backlog (birikme) modelleme\n",
        "\n",
        "## ğŸš€ Ã–ne Ã‡Ä±kan Analizler\n",
        "\n",
        "### 1. Depo ve Sorter SimÃ¼lasyonu\n",
        "* SipariÅŸ hacminde gerÃ§ekleÅŸecek **%20'lik bir artÄ±ÅŸÄ±n**, mevcut sorter kapasitesiyle yÃ¶netilemeyeceÄŸi ve operasyonel birikmeye (backlog) yol aÃ§acaÄŸÄ± kanÄ±tlanmÄ±ÅŸtÄ±r.\n",
        "* GÃ¼nlÃ¼k ortalama kapasite sÄ±nÄ±rlarÄ± belirlenerek, yoÄŸun kampanya dÃ¶nemleri iÃ§in kaynak planlamasÄ± Ã¶nerileri sunulmuÅŸtur.\n",
        "\n",
        "### 2. Teslimat Gecikmesi Tahminleme (ML)\n",
        "* **Model:** XGBoost Classifier\n",
        "* **Performans:** %82 Precision (Gecikme tahminlerinde yÃ¼ksek doÄŸruluk).\n",
        "* **Kritik Bulgular:** Gecikmelerin en bÃ¼yÃ¼k nedeninin Ã¼rÃ¼n tÃ¼rÃ¼nden ziyade **Order City (%31)** ve **Sales per customer (%30)** olduÄŸu saptanmÄ±ÅŸtÄ±r.\n",
        "\n",
        "## ğŸ“Š Dashboard ve GÃ¶rselleÅŸtirme\n",
        "Proje kapsamÄ±nda hazÄ±rlanan gÃ¶rselleÅŸtirmeler ÅŸunlarÄ± iÃ§erir:\n",
        "* **Hata Matrisi (Confusion Matrix):** Modelin tahmin baÅŸarÄ±sÄ±nÄ±n gÃ¶rsel analizi.\n",
        "* **Feature Importance:** Lojistik performansÄ±nÄ± etkileyen en kritik deÄŸiÅŸkenlerin sÄ±ralamasÄ±.\n",
        "* **Backlog Trendi:** Kapasite aÅŸÄ±mÄ± durumunda sipariÅŸlerin gÃ¼nlere gÃ¶re birikme grafiÄŸi.\n",
        "\n",
        "## ğŸ“‚ Dosya YapÄ±sÄ±\n",
        "* `DataCoSupplyChainDataset.csv`: Ham veri seti (Kaggle).\n",
        "* `logistic_analysis.ipynb`: Veri temizleme, simÃ¼lasyon ve ML kodlarÄ±.\n",
        "* `dashboard_hazir_veri.csv`: BI araÃ§larÄ± iÃ§in temizlenmiÅŸ metrikler.\n",
        "\n",
        "## ğŸ“ˆ SonuÃ§ ve Ã–neriler\n",
        "1. **YÃ¼ksek Riskli Åehirler:** Belirli lokasyonlardaki lojistik aÄŸÄ±nÄ±n yeniden optimize edilmesi gerekmektedir.\n",
        "2. **HÄ±zlÄ± GeÃ§iÅŸ (Fast Track):** Modelin \"Gecikme Riski\" verdiÄŸi yÃ¼ksek tutarlÄ± sipariÅŸlerin depoda Ã¶nceliklendirilmesi Ã¶nerilir.\"\"\"\n",
        "\n",
        "with open(\"README.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "print(\"README.md baÅŸarÄ±yla oluÅŸturuldu!\")"
      ],
      "metadata": {
        "id": "5iQi_gdh_1bT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}